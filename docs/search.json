[
  {
    "objectID": "posts/402-case2-pk/402-case2-pk.html",
    "href": "posts/402-case2-pk/402-case2-pk.html",
    "title": "Pharmacokinetic exposure by ethnicity",
    "section": "",
    "text": "This case study is inspired by a publication comparing the pharmacokinetic exposure of a drug in Caucasian vs. Japanese subjects. The same single oral dose was administered to all subjects. The original graph displays mean +/- standard deviations (SD) of the plasma concentration over time, grouped by ethnicity (Caucasian or Japanese).\nAfter reading in and performing a number of small number of data transformations we recreate the original graph in Figure 1.\n\nmy_data &lt;- read_csv(\"../../data/402_case2_PKdataset.csv\") %&gt;%\n  filter(CMT == 2 & DOSE == 300 & PART == 1 & STUDY == 1) %&gt;%\n  mutate(\n    TRTACT = factor(TRTACT, levels = rev(unique(TRTACT[order(DOSE)]))),\n    ETHN = factor(ETHN),\n    ETHN = factor(ETHN, levels = rev(levels(ETHN)))\n  )\n\n\n## Plot mean and error bars (SD) on a linear scale\nmy_data %&gt;%\n  ggplot(aes(\n    x = NOMTIME,\n    y = LIDV,\n    group = interaction(ETHN, CYCLE)\n  )) +\n  stat_summary(\n    geom = \"errorbar\",\n    width = 2,\n    fun.data = mean_sdl,\n    fun.args = list(mult = 1)\n  ) +\n  stat_summary(geom = \"line\", size = 0.5,\n               fun.y = mean) +\n  stat_summary(\n    aes(fill = ETHN),\n    geom = \"point\",\n    size = 1.5,\n    fun.y = mean,\n    stroke = 0.5,\n    shape = 21\n  ) +\n  scale_fill_manual(values = c(\"white\", \"black\")) +\n  scale_x_continuous(breaks = c(0, 4, 8, 12, 24, 36, 48, 72)) +\n  xlab(\"Time (h)\") +\n  ylab(\"Concentration (ng/mL)\\nMean (SD)\") +\n  theme_bw(base_size = 8) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"bottom\",\n    legend.box.spacing = unit(0, \"mm\")\n  )\n\n\n\n\nPharmacokinetic exposure by ethnicity.\n\n\n\n\nThis time, let us start with Law 1. What is the purpose of this graph? For drugs that are mainly developed in a Caucasian population, Japanese drug regulation requires sponsors to investigate whether the pharmacokinetics (PK) are similar or different between Caucasian and Japanese populations. The purpose of this graph is to help address this question. Looking at it, we may be tempted so say that the PK are reasonably similar. But are they really? If they are not, then in what way?\nThis leads us to Law 2: show the data clearly. The graphical attributes in Figure 1 appear to be wisely chosen: the symbols and labels are clear, the gridlines are supportive and stay in the background, and there is no unnecessary adornment. However, at least two things obscure the answer to our question of interest. First, the concentrations are plotted on a linear scale, which makes it difficult to distinguish them at the lower end of the profile. Concentrations should be plotted on a logarithmic scale because they are log-normally distributed. In fact, for concentrations in particular (but not generally for any log-normally distributed data) we should produce both types of display: one on a log-linear scale (to assess the elimination phase) and one on a linear scale (to see the peak more clearly). Second, it is hard to determine whether any differences are significant when standard deviations are plotted instead of standard errors or confidence intervals. Standard deviations show the variation in the data; they do not shrink when more data is collected. Standard errors show the variation in the means. Confidence intervals may be the best choice as they directly show the uncertainty about the means.\n\n## Mean (95% CI) error bars, log scale\nmy_data %&gt;%\n  ggplot(aes(\n    x = NOMTIME,\n    y = LIDV,\n    group = interaction(ETHN, CYCLE)\n  )) +\n  stat_summary(\n    geom = \"errorbar\",\n    width = 2,\n    fun.data = mean_cl_normal,\n    fun.args = list(mult = 1)\n  ) +\n  stat_summary(geom = \"line\", size = 0.5,\n               fun.y = mean) +\n  stat_summary(\n    aes(fill = ETHN),\n    geom = \"point\",\n    size = 1.5,\n    fun.y = mean,\n    stroke = 0.5,\n    shape = 21\n  ) +\n  scale_fill_manual(values = c(\"white\", \"black\")) +\n  scale_x_continuous(breaks = c(0, 4, 8, 12, 24, 36, 48, 72)) +\n  xlab(\"Time (h)\") + ylab(\"Concentration (ng/mL)\\nMean (95% CI)\") +\n  guides(color = guide_legend(title = \"Dose\")) +\n  scale_y_log10() +\n  annotation_logticks(base = 10,\n                      sides = \"l\",\n                      color = rgb(0.5, 0.5, 0.5)) +\n  theme_bw(base_size = 8) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"bottom\",\n    legend.box.spacing = unit(0, \"mm\")\n  )\n\n\n\n\nFigure 1 looks fair at first sight but reveals important information after two simple changes, namely, scaling the y-axis differently and plotting confidence intervals instead of standard deviations\n\n\n\n\nThese issues have been fixed in Figure 2 (we only show the log-linear version). To reduce cluttering, the ticks at the end of the whiskers have also been omitted (non-data ink). If the graph displayed more than two profiles, we might consider replacing the whiskers by (shaded) confidence bands, or separating the graph out in panels or “small multiples” (see bottom of the backside of the Cheat Sheet. From Figure 8B it appears that the higher concentrations are not meaningfully different, but the elimination phase does differ between the two ethnicities. This could also translate to different average exposures. That is, based on two simple changes in the plot, we now see answers emerging for our initial question about PK differences. We see them emerging with respect to three key PK characteristics: peak, elimination/trough, and overall exposure. While (depending on the drug) similarity in the peak may be reassuring from a safety point of view, a lower overall exposure in Japanese subjects could be a concern for efficacy.\nMoving on to Law 3, let us now make the message obvious. We could choose a completely different graph type to hone in on the message. Figure 3 shows the three (non-compartmentally derived) quantities Cmax, Ctrough and AUClast with 95% confidence intervals by ethnicity. Clearly, Ctrough and AUC are different between the two ethnicities, but Cmax is not. We could derive these quantities from a compartmental model fit and produce the same plot. Or we could go one step further and show directly their geometric mean ratio, Japanese vs. Caucasian subjects, as in Figure 8D. This last plot answers the initial question most succinctly, and its graphical appearance has also been further simplified (no frame, minimal gridlines, mildly highlighted line of equality), to not distract from the message. In practice, Figures 2, 3 and/or 4 together may be most informative, covering the time course as well as differences in key parameters.\n\ntheme_set(theme_bw(base_size = 10))\n\n## Plot cmax, ctrough, AUClast dots (95% CI) in separate panels\n\nCmax &lt;- my_data %&gt;%\n  filter(!is.na(LIDV))  %&gt;%\n  group_by(ID, ETHN) %&gt;%\n  summarize(Cmax = max(LIDV),\n            Ctrough = min(LIDV))\n\nCtrough &lt;- my_data %&gt;%\n  filter(!is.na(LIDV))  %&gt;%\n  group_by(ID, ETHN) %&gt;%\n  summarize(Ctrough = min(LIDV))\n\nAUClast &lt;- my_data %&gt;%\n  filter(!is.na(LIDV))\n\nAUClast &lt;-\n  data.frame(stack(sapply(split(AUClast, AUClast$ID), function(df)\n    trapz(df$TIME, df$LIDV))))\nnames(AUClast) &lt;- c(\"AUC\", \"ID\")\n\nAUClast$ID &lt;- as.numeric(as.character(AUClast$ID))\nAUClast &lt;- AUClast[order(AUClast$ID),]\nAUClast &lt;-\n  merge(AUClast, unique(my_data[c(\"ID\", \"ETHN\")]), by = \"ID\")\n\n\ngg1 &lt;- Cmax %&gt;%\n  ggplot(aes(x = ETHN, y = Cmax, group = ETHN)) +\n  stat_summary(fun.data = mean_cl_normal,\n               geom = \"errorbar\",\n               width = 0) +\n  stat_summary(shape = 21, fill = \"white\", size = 0.2) +\n  labs(title = \"Cmax (ng/mL)\", subtitle = \"Mean (95% CI)\") +\n  scale_y_log10(breaks = c(0.3, 1, 3, 10, 30, 100, 300, 1000, 3000),\n                limits = c(60, 300)) +   annotation_logticks(base = 10,\n                                                             sides = \"l\",\n                                                             color = rgb(0.5, 0.5, 0.5)) +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.subtitle = element_text(color = rgb(0.3, 0.3, 0.3))\n  )\n\ngg2 &lt;- gg1 %+% #Cmax %+%\n  aes(x = ETHN, y = Ctrough) +\n  labs(title = \"Ctrough (ng/mL)\") +\n  scale_y_log10(breaks = c(0.3, 1, 3, 10, 30, 100, 300, 1000, 3000),\n                limits = c(0.6, 9))\n\n\ngg3 &lt;- gg1 %+% AUClast %+% aes(x = ETHN, y = AUC) +\n  labs(title = \"AUClast (h.(ng/mL))\") +\n  scale_y_log10(breaks = c(0.3, 1, 3, 10, 30, 100, 300, 1000, 3000),\n                limits = c(500, 1500))\n\ngrid.arrange(arrangeGrob(gg1, gg2, gg3, nrow = 1), nrow = 1)\n\n\n\n\nKey messages are made more obvious by directly plotting the pharmacokinetic parameters of interest.\n\n\n\n\n\nCmax2  &lt;- Cmax %&gt;%\n  mutate(DV = Cmax,\n         logDV = log(Cmax),\n         LABEL = \"Cmax\") %&gt;%\n  select(c(\"ID\", \"ETHN\", \"DV\", \"logDV\", \"LABEL\"))\n\nresults &lt;- t.test(logDV ~ ETHN, Cmax2)\n\nPKmetrics &lt;- data.frame(\n  y2.5 = exp(results$conf.int[1]),\n  y97.5 = exp(results$conf.int[2]),\n  ymean = exp(as.numeric(results$estimate[1] - results$estimate[2])),\n  var = \"Cmax\",\n  unit = \"ng/mL\"\n)\n\nCtrough2 &lt;- Ctrough %&gt;%\n  mutate(DV = Ctrough,\n         logDV = log(Ctrough),\n         LABEL = \"Ctrough\") %&gt;%\n  select(c(\"ID\", \"ETHN\", \"DV\", \"logDV\", \"LABEL\"))\n\nresults &lt;- t.test(logDV ~ ETHN, Ctrough2)\n\nPKmetrics &lt;- rbind(\n  PKmetrics,\n  data.frame(\n    y2.5 = exp(results$conf.int[1]),\n    y97.5 = exp(results$conf.int[2]),\n    ymean = exp(as.numeric(results$estimate[1] - results$estimate[2])),\n    var = \"Ctrough\",\n    unit = \"ng/mL\"\n  )\n)\n\nAUClast2 &lt;- AUClast %&gt;%\n  mutate(DV = AUC,\n         logDV = log(AUC),\n         LABEL = \"AUClast\") %&gt;%\n  select(c(\"ID\", \"ETHN\", \"DV\", \"logDV\", \"LABEL\"))\n\nresults &lt;- t.test(logDV ~ ETHN, AUClast2)\n\nPKmetrics &lt;- rbind(\n  PKmetrics,\n  data.frame(\n    y2.5 = exp(results$conf.int[1]),\n    y97.5 = exp(results$conf.int[2]),\n    ymean = exp(as.numeric(results$estimate[1] - results$estimate[2])),\n    var = \"AUClast\",\n    unit = \"h.ng/mL\"\n  )\n)\n\nPKmetrics$var &lt;-\n  factor(PKmetrics$var, levels = c(\"AUClast\", \"Ctrough\", \"Cmax\"))\n\nPKmetrics %&gt;%\n  ggplot(aes(\n    x = var,\n    y = ymean,\n    ymin = y2.5,\n    ymax = y97.5\n  )) +\n  paper_theme() +\n  geom_hline(\n    yintercept = 1,\n    size = 1,\n    colour = \"red\",\n    alpha = 0.1\n  ) +\n  scale_y_log10(breaks = c(0.25, 0.5, 1, 2, 4)) +\n  geom_point() +\n  geom_errorbar(width = 0) +\n  xlab(\"\") +\n  scale_x_discrete(breaks = NULL, labels = NULL) +\n  ylab(\"Ratios between Japanese and Caucasian Mean (95% CI)\") +\n  geom_text(aes(\n    x = var,\n    y = 0.175,\n    label = paste0(var, \"\\n(\", unit, \")\")\n  )) +\n  theme(\n    panel.grid.major.x = element_line(color = \"gray\", size = 0.2),\n    panel.grid.major.y = element_blank(),\n    panel.border = element_blank(),\n    axis.title.x = element_text(size = 11, vjust = -1.25),\n    axis.title.y = element_blank()\n  ) +\n  coord_flip(ylim = c(0.15, 5)) \n\n\n\n\nOr even only their ratios: Forest plot of Ratios of Japanese:Caucasian for Cmax, Ctrough, AUClast\n\n\n\n\n\nsessionInfo()\n\n## R version 4.3.0 (2023-04-21)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Ventura 13.6.3\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: Europe/Zurich\n## tzcode source: internal\n## \n## attached base packages:\n## [1] grid      stats     graphics  grDevices utils    \n## [6] datasets  methods   base     \n## \n## other attached packages:\n##  [1] data.table_1.14.8  gridExtra_2.3     \n##  [3] caTools_1.18.2     RColorBrewer_1.1-3\n##  [5] lubridate_1.9.2    forcats_1.0.0     \n##  [7] stringr_1.5.0      dplyr_1.1.2       \n##  [9] purrr_1.0.1        readr_2.1.4       \n## [11] tidyr_1.3.0        tibble_3.2.1      \n## [13] ggplot2_3.4.2      tidyverse_2.0.0   \n## [15] distill_1.6       \n## \n## loaded via a namespace (and not attached):\n##  [1] gtable_0.3.3      xfun_0.39         htmlwidgets_1.6.2\n##  [4] tzdb_0.4.0        vctrs_0.6.2       tools_4.3.0      \n##  [7] bitops_1.0-7      generics_0.1.3    parallel_4.3.0   \n## [10] fansi_1.0.4       cluster_2.1.4     pkgconfig_2.0.3  \n## [13] checkmate_2.2.0   lifecycle_1.0.3   farver_2.1.1     \n## [16] compiler_4.3.0    munsell_0.5.0     htmltools_0.5.5  \n## [19] yaml_2.3.7        htmlTable_2.4.1   Formula_1.2-5    \n## [22] pillar_1.9.0      crayon_1.5.2      cachem_1.0.8     \n## [25] Hmisc_5.1-0       rpart_4.1.19      tidyselect_1.2.0 \n## [28] digest_0.6.31     stringi_1.7.12    labeling_0.4.2   \n## [31] fastmap_1.1.1     colorspace_2.1-0  cli_3.6.1        \n## [34] magrittr_2.0.3    base64enc_0.1-3   utf8_1.2.3       \n## [37] foreign_0.8-84    withr_2.5.0       scales_1.2.1     \n## [40] backports_1.4.1   bit64_4.0.5       timechange_0.2.0 \n## [43] rmarkdown_2.22    bit_4.0.5         nnet_7.3-18      \n## [46] hms_1.1.3         memoise_2.0.1     evaluate_0.21    \n## [49] knitr_1.43        rlang_1.1.1       downlit_0.4.3    \n## [52] glue_1.6.2        rstudioapi_0.14   vroom_1.6.3      \n## [55] jsonlite_1.8.4    R6_2.5.1"
  },
  {
    "objectID": "posts/301-cheatsheet/301-cheatsheet.html",
    "href": "posts/301-cheatsheet/301-cheatsheet.html",
    "title": "Graphics Principles Cheat Sheet",
    "section": "",
    "text": "The three laws outlined here provide overarching principled advice, and should serve as a guiding star towards effective visual communication for the quantitative scientist. To further ease their implementation in practice, it helps to distill even more detailed recommendations and to illustrate them concretely.\nTo this end, we have introduced the Graphics Principles Cheat Sheet.This single-page reference sheet is an integral part of this tutorial. It was carefully designed as a concise and accessible resource for everyday practical use. Yet, it draws from a wide range of sources. We hope that it proves useful for putting the three laws into practice.\nThe full version is available along with corresponding programming code in R."
  },
  {
    "objectID": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html",
    "href": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html",
    "title": "Three laws of visual communication",
    "section": "",
    "text": "Why? (Sinek 2009; Bonate 2014) What is the purpose of this display or that communication? Doumont (Jean L. Doumont 2002) states this as the “zeroth law” of professional communication, “a principle so obvious that it had long been overlooked”. Be clear and explicit about what you want to achieve. Is it to explore some data, to convey an inferential analysis, to deliver a message, convince an audience, or support a decision? It may be a mixture of these – for example, even seemingly simple exploratory plots should serve some (perhaps implicit) decision (e.g. on how to explore further). Every graph, and more generally every communication, must be tailored to its specific purpose.\nIt helps to carve out the scientific question you are trying to address, ideally in discussion with partners, and to write it down explicitly. Try not to look at any data before. This is the concept of “question-based visualizations”(Vandemeulebroecke et al. 2019): let the scientific question determine what data to display and how. (For example, combine data from different domains if it helps address the question effectively. Do not only produce standard outputs by data domain – a display should be determined by the question it addresses, not by the way the data is organized.). As Diggle (Diggle 2018) put it, we “analyze problems, not data”. This does not mean that the question could not be refined after seeing the data. We may well iterate over the problem space and the solution space – as long as we do it consciously. Senn (Senn 2008) illustrates many examples of wrongly framed research questions. A common one is to focus on the wrong comparison, such as comparing a post-treatment value to the corresponding baseline value instead of to the value under a control treatment. Most quantitative graphs display comparisons (Gelman, Pasarica, and Dodhia 2002), and it always helps to ask “compared to what?” (Tufte 1986). If the comparison is not clear to the author, it will also not be clear to the reader.\nPart of this first law (and of the third, see below) is also to be clear about your audience. Then, to adapt to your audience. Do not assume it will adapt to you. You cannot control your audience, but you can control what information and messages you deliver to it, and how. Is your audience just you (trying to see patterns in data), you in a few years (trying to remember what you did), quantitative experts such as your peers (interested in your methods), subject matter experts (eager for your main message), decision-makers (headlines only), or a mixture of these? Your visual communication will need to be different accordingly. Your communication (plot, presentation, report) is for the audience, not for you.\nClarity on the purpose and the scientific question of interest will help choose appropriate quantitative methods to address them. This, plus clarity on your audience, will help define the key messages and how to deliver them. (On the aspect of delivery see also Law 3 below.)\nOf note, this first law is so important that it may occasionally defy other good principles. If your primary goal is to catch attention, then you may choose an iconic graphical representation that does this well, even if it violates some of the recommendations given further below (Gelman and Unwin 2013). However, you should never distort the data."
  },
  {
    "objectID": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-1-have-a-clear-purpose",
    "href": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-1-have-a-clear-purpose",
    "title": "Three laws of visual communication",
    "section": "",
    "text": "Why? (Sinek 2009; Bonate 2014) What is the purpose of this display or that communication? Doumont (Jean L. Doumont 2002) states this as the “zeroth law” of professional communication, “a principle so obvious that it had long been overlooked”. Be clear and explicit about what you want to achieve. Is it to explore some data, to convey an inferential analysis, to deliver a message, convince an audience, or support a decision? It may be a mixture of these – for example, even seemingly simple exploratory plots should serve some (perhaps implicit) decision (e.g. on how to explore further). Every graph, and more generally every communication, must be tailored to its specific purpose.\nIt helps to carve out the scientific question you are trying to address, ideally in discussion with partners, and to write it down explicitly. Try not to look at any data before. This is the concept of “question-based visualizations”(Vandemeulebroecke et al. 2019): let the scientific question determine what data to display and how. (For example, combine data from different domains if it helps address the question effectively. Do not only produce standard outputs by data domain – a display should be determined by the question it addresses, not by the way the data is organized.). As Diggle (Diggle 2018) put it, we “analyze problems, not data”. This does not mean that the question could not be refined after seeing the data. We may well iterate over the problem space and the solution space – as long as we do it consciously. Senn (Senn 2008) illustrates many examples of wrongly framed research questions. A common one is to focus on the wrong comparison, such as comparing a post-treatment value to the corresponding baseline value instead of to the value under a control treatment. Most quantitative graphs display comparisons (Gelman, Pasarica, and Dodhia 2002), and it always helps to ask “compared to what?” (Tufte 1986). If the comparison is not clear to the author, it will also not be clear to the reader.\nPart of this first law (and of the third, see below) is also to be clear about your audience. Then, to adapt to your audience. Do not assume it will adapt to you. You cannot control your audience, but you can control what information and messages you deliver to it, and how. Is your audience just you (trying to see patterns in data), you in a few years (trying to remember what you did), quantitative experts such as your peers (interested in your methods), subject matter experts (eager for your main message), decision-makers (headlines only), or a mixture of these? Your visual communication will need to be different accordingly. Your communication (plot, presentation, report) is for the audience, not for you.\nClarity on the purpose and the scientific question of interest will help choose appropriate quantitative methods to address them. This, plus clarity on your audience, will help define the key messages and how to deliver them. (On the aspect of delivery see also Law 3 below.)\nOf note, this first law is so important that it may occasionally defy other good principles. If your primary goal is to catch attention, then you may choose an iconic graphical representation that does this well, even if it violates some of the recommendations given further below (Gelman and Unwin 2013). However, you should never distort the data."
  },
  {
    "objectID": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-2-show-the-data-clearly",
    "href": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-2-show-the-data-clearly",
    "title": "Three laws of visual communication",
    "section": "Law 2: Show the data clearly",
    "text": "Law 2: Show the data clearly\nThis is Tufte’s maxim (Tufte 1986): “Above all else, show the data”. Show it accurately and clearly. This law has several faces:\n\nSimplify! “Simplify to clarify” (B. Wong 2011). It is the prime task of quantitative scientists to make the complex simple: reveal structure in data through models, make inference through analyses, distill and convey conclusions through (visual) communication. Choose the simplest appropriate graph type; prefer familiar designs over fancy ones (see also the Cleveland-McGill effectiveness ranking in Law 3 below). Avoid fake dimensions. Make your plot “as simple as it can be, but not simpler” (attributed to Albert Einstein; also “Occam’s razor” or the law of parsimony). “Understand, edit and simplify the information and design with your readers in mind” (D. M. Wong 2010). Do not be confused: it is hard to make things simple. This is an iterative process: “edit and revise” (Tufte 1986), and repeat.\nMaximize the data-to-ink ratio (also “data density index” (Tufte 1986)) within reason. Maximize the signal over the noise by removing the noise: remove anything that distracts from the purpose of the graph. Nothing is neutral: the choice of symbols or colors, background, fonts, line style, annotations. These elements are noise if they do not serve a clear purpose. Choose them wisely and parsimoniously; make the data stand out. Do not trust defaults in graphical software packages. Often, intelligent use of white space can structure a display better than a lot of ink. (The same holds for tables: these are often most effectively structured by reserving black lines for the horizontal direction and using simple alignment in the vertical direction.) Never clutter your graph with “chart junk” (Tufte 1997).\nDisplay the relevant data directly. In a quantitative workflow, this often means to look at the raw data and not just rely on summary statistics. Cabanski8 illustrates this with nine datasets that show completely different patterns despite identical marginal means, standard deviations and correlation coefficients (see also Anscombe (Anscombe 1973) and Matejka and Fitzmaurice (Matejka and Fitzmaurice 2017)). Ask yourself what is the best way of summarizing the relevant features of the data; it may not be the mean +/- standard error. When fitting a (statistical, compartmental, mechanistic etc.) model to the data to draw inference or make predictions, model-derived quantities may be the relevant data to display. In this case a plot of the raw data may be misleading if it does not account for important covariates. In a final communication, display concisely what best supports your message (see also below, Law 3).\n\n\nknitr::include_graphics(\"Figure1b.png\")\n\n\n\n\nLaw 2, show the data clearly. The pie and donut charts in panels A and B make it difficult to see the order of magnitude of some of the segments. The eye needs to compare areas, bent lengths (of the contour) or angles, graphical attributes that are not easily decoded. The donut chart even omits the angles. The mosaic plot in panel C only relies on areas; again it is hard to tell the order of magnitude. It is better to use lengths with a common baseline or positions on a common scale, such as in a barchart or dotplot (see Cleveland-McGill effectiveness ranking in Law 3). The barchart in panel D however introduces a fake dimension, which is unnecessary and makes it hard to decode the numerical values from the height of the bars. Panels E and F are appropriately simple and show the data clearly. They also order the data by magnitude to aid comparison even further. The dotplot in panel F uses minimal amount of ink and draws the eye to the position of the dots; it is the most effective way of displaying this data.\n\n\n\n\nFigure 1 illustrates some aspects of this second law. Wainer (Wainer 1984) has turned this law around, noting that “methods for displaying data badly have been developed for many years, and a wide variety of interesting and inventive schemes have emerged”. He provides 12 highly amusing rules for “how to display data badly”, with striking examples. He then concludes more seriously: “The rules for good display are quite simple. Examine the data carefully enough to know what they have to say, and then let them say it with a minimum of adornment. Do this while following reasonable regularity practices in the depiction of scale, and label clearly and fully.”"
  },
  {
    "objectID": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-3-make-the-message-obvious",
    "href": "posts/201-three-laws-vizcom/201-three-laws-vizcom.html#law-3-make-the-message-obvious",
    "title": "Three laws of visual communication",
    "section": "Law 3: Make the message obvious",
    "text": "Law 3: Make the message obvious\nIf the second law focused on the data (with a tendency to reduce noise), then the third is all about the message (and amplifying the signal). This assumes that you do have a message to tell, and that this message is clear at least to yourself. If there is any doubt on this, return to the first law.\nThe third law mandates to make your message as obvious as possible. Quoting Krzywinski and Cairo (Krzywinski and Cairo 2013), “inviting readers to draw their own conclusions is risky”. Do not only make your message easy to get. Make it impossible to miss. This extends beyond graphical elements and involves all aspects of communication.\nClarity on your audience, mentioned already in the first law, is also a prerequisite for the third. It is needed for carving out the message to tell (Law 1) and for adapting its way of delivery (Law 3).\nSpecific examples for the third law include the following:\n\nChoose wisely how to encode the data you display. Color and area are good for drawing attention, but a viewer can decode positions on a common scale much more easily and accurately. Consider the effectiveness ranking of graphical attributes for encoding numerical values, as proposed by Cleveland and McGill [Cleveland (1985); Cleveland (1984); Cleveland.McGill1984; Cleveland1987; Cleveland and McGill (1985)] (see also Cairo (Cairo 2016), Munzner (Munzner 2015), and Heer and Bostock (Heer and Bostock 2010)). See here for an overview of this ranking.\nExploit pre-attentive processing as much as possible (Few 2012; Ware 2004). Some graphical features “jump to the eye” while others require careful inspection. Consider this in your choice of how to encode the data (Cleveland-McGill effectiveness ranking, see above) and in your choice of symbols, colors, line types etc. See here for an illustration.\nAvoid mental arithmetic. If differences or ratios are the main interest, show them directly. If both raw values and differences are of interest, consider showing both.\nExploit the principles of visual grouping (B. Wong 2010). Graphical entities are most effectively grouped by enclosure, connection, proximity and similarity (in this order). That is, similar objects are perceived as belonging together, as are objects close to each other, connected by lines, or enclosed in a common subspace. See Figure 3 for an illustration: these mechanisms can provide contextual information to a plot in a simple yet powerful way.\nMinimize the viewer’s eye movement. Place elements that are to be compared close to each other. Prefer direct labelling over a legend. See also here.\nDraw the reader’s attention to the main points. Use appropriate graphical features (e.g. bold or colored highlighting, reference lines, circling etc.). Follow up with explicit labelling (e.g. “treatment A outperforms treatment B by X%”).\nAdd meaningful information to a graph to tell the whole story. E.g., include reference lines, benchmark effects, inferences etc.\nUse effective redundancy. Convey the same message through multiple channels, to amplify it and give the audience a second chance to get it. Use words and pictures in unison (J. L. Doumont 2009). E.g., in addition to showing the data, consider annotating the “good” or “bad” axis direction, and state what is seen in plain words. Do not confuse redundancy (pointlessly cluttering the graph) with effective redundancy (conveying a message through multiple complementary channels).\nLet every plot stand on its own. Use informative labels and captions, and explain abbreviations. Do not require the reader to search through text in order to understand a figure.\nAlways add a title to your plot. Phrase it as a conclusion, not a description (e.g. “plasma concentration depends on body weight” rather than “plot of plasma concentration vs. body weight”)."
  },
  {
    "objectID": "posts/403-case3-waterfall/403-case3-waterfall.html",
    "href": "posts/403-case3-waterfall/403-case3-waterfall.html",
    "title": "Why a waterfall plot?",
    "section": "",
    "text": "This case study illustrates the importance of aligning a graph with the scientific question it should address, the option of filtering signals through a model, and finally the display of a scientific answer in a condensed messaging graph.\nConsider a small early development trial, randomized and placebo-controlled (2:1 randomization), with a continuous primary endpoint measured at baseline and longitudinally over a period of 4 weeks. Lower outcome values are better, and there are no dropouts and no missing data. Suppose that the team is interested in the effect of the drug at the last measurement time point, as it is often the case. A common approach in early development trials is to simply plot the observed change scores in a so-called “waterfall plot” such as Figure 1.\n\nggplot(t4dat, aes(x = sort_id, y = cfb, fill = factor(ztext))) +\n  geom_col(alpha = 0.8) +\n  scale_fill_brewer(palette = \"Dark2\", name = \"Treatment\") +\n  paper_theme() +\n  theme(\n    legend.position = c(0.8, 0.2),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.border = element_rect(color = \"grey\", fill = NA)\n  ) +\n  labs(x = \"Subject\", y = \"Change from baseline\",\n       title = \"Week 4 outcome by treatment\")\n\n\n\n\nWaterfall plot of week 4 outcome\n\n\n\n\nTo probe Law 1, what is the question addressed by this plot? It asks about the treatment effect after 4 weeks of treatment. Is this the right question? Let us assume for a moment that it is. Then a waterfall plot is not ideal for addressing it. Small treatment effects are difficult to discern, especially with an unbalanced randomization ratio. The audience must observe the distribution of color across the entire plot just to determine which treatment is more beneficial; this can become even more difficult with a larger sample size or more than two treatment groups. In Figure 1, one might see a treatment benefit, but how large is it and how certain of it are we? The popularity of waterfall plots is a mystery.\nIf we insist on week 4 as the only time point of interest, we could present overlaid density plots or side-by-side boxplots for a better appreciation of the difference in distribution between the two treatment arms. Figure 2 shows an example with the raw data points included, which is a much better alternative to Figure 1. The side-by-side placement facilitates the treatment comparison, and the plot is simple, familiar and uses minimal ink for what it shows. Graphical attributes (colors, font size, etc.) are easily readable.\n\nggplot(data = t4dat, aes(x = ztext, y = cfb, colour = ztext)) +\n  geom_boxplot(width = 0.25) +\n  geom_jitter(alpha = 0.25, width = 0.1) +\n  scale_colour_brewer(palette = \"Dark2\") +\n  labs(x = \"\", y = \"Change from baseline\") +\n  paper_theme() +\n  theme(legend.position = \"none\") +\n  labs(x = \"\", y = \"Change from baseline\",\n       title = \"Week 4 outcome\") +\n  theme(\n    panel.border = element_rect(color = \"grey\", fill = NA, size = 0.25),\n    plot.title = element_text(size = 12),\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 10),\n    axis.title.y = element_text(size = 10),\n    axis.ticks.x = element_blank(),\n    panel.grid.major.x = element_blank()\n  )\n\n\n\n\nBoxplots of week 4 outcome\n\n\n\n\nHowever, with such rich longitudinal data, it may be more informative to ask the question about the treatment effect during – not just after – the first 4 weeks of treatment. This is especially relevant in the early, more exploratory development phase (and it would be even more relevant if there were dropouts). As a rule, the recommended first step is to visualize the totality of the data. Figure 3 does this and includes means by treatment and time point. We see large inter-individual variability and overlap between the treatment groups. We also start to get an appreciation for the time-course of a mean effect. We see linear trajectories of the means over time, with the active arm appearing to improve and the placebo arm staying fairly constant. We cannot exclude that the apparent gap might continue to increase beyond 4 weeks of treatment. This plot, while doing little more than displaying the raw data, is already worth sharing with the project team. It facilitates a much richer understanding of the data than the previous two plots. It shows the data clearly i.e. Law 2.\n\nmd &lt;- dres %&gt;%\n  group_by(time, ztext) %&gt;%\n  summarise(\n    m = mean(y),\n    s = sd(y),\n    n = n(),\n    se = s / sqrt(n)\n  )\n\nggplot() +\n  theme(legend.position = c(0.8, 0.65),\n        legend.background = element_blank()) +\n  geom_line(data = dres,\n            aes(\n              x = time,\n              y = y,\n              group = id,\n              colour = factor(ztext)\n            ),\n            alpha = 0.35) +\n  geom_line(data = md,\n            aes(\n              x = time,\n              y = m,\n              colour = factor(ztext)\n            ),\n            size = 1) +\n  geom_point(data = md, aes(\n    x = time,\n    y = m,\n    ymin = m - s,\n    ymax = m + s,\n    colour = ztext\n  )) +\n  scale_y_continuous(limits = c(min(dres$y) - 2.5, max(dres$y))) +\n  scale_colour_brewer(palette = \"Dark2\", name = \"\") +\n  labs(x = \"Week\", y = \"Outcome\",\n       title = \"Longitudinal individual outcomes \\nwith group means\") +\n  paper_theme() +\n  theme(\n    panel.border = element_rect(color = \"grey\", fill = NA, size = 0.25),\n    plot.title = element_text(size = 10),\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 8),\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10),\n    legend.position = c(0.15, 0.225),\n    legend.background = element_blank()\n  )\n\n\n\n\nSpaghetti plots & mean +/- SD\n\n\n\n\nDepending on the goal of the analysis, we could stop here. But if we want to quantify the treatment difference while adjusting for important covariates, we should proceed with a statistical model. Based on Figure 3 a linear model appears appropriate. We fit a linear model with treatment, patient-specific intercept and slope, and we now also adjust for the baseline value of the primary endpoint and for any other important covariates. We can then visualize the data filtered through this model, omitting the raw data but displaying longitudinal point estimates and some form of uncertainty intervals for both treatment groups (Figure 4). This gets closer to the nature of a messaging graph, focusing directly on the results of our model. Optionally – and depending on the audience! – we could even go one final step further and display the treatment difference directly, as in Figure 5. This plot addresses the question about the treatment effect over time without requiring any mental arithmetic. We can read off approximate estimates for the treatment effect, and the level of confidence is easily appreciable from the added confidence band (which does include zero!). Appropriate and parsimonious annotations make the message even more obvious, Law 3, also through “effectively redundant” information (stating what can be seen).\n\n## Model fit to longtiduinal data\nadat &lt;- dres %&gt;%\n  filter(time &gt; 0)\n\nmod &lt;-\n  stan_lmer(\n    y ~ time * factor(z) + baseline + x1 + x2 + (time | id),\n    data = adat,\n    chains = 4,\n    iter = 500,\n    cores = 4\n  )\n\nnd1 &lt;- dres %&gt;%\n  select(id, time, baseline, x1, x2, z)\n\nnd2 &lt;- dres %&gt;%\n  select(id, time, baseline, x1, x2, z) %&gt;%\n  mutate(z = 1 - z)\n\nnd &lt;- bind_rows(nd1, nd2) %&gt;%\n  arrange(id, time, z)\n\nprs &lt;- c(0.05, 0.5, 0.95)\n\nppnd &lt;- nd %&gt;% select(id, time, z) %&gt;%\n  bind_cols(as_tibble(t(\n    posterior_linpred(mod, newdata = nd, re.form =  ~ 0)\n  ))) %&gt;%\n  gather(4:1003, key = \"ppid\", value = \"ypred\") %&gt;%\n  spread(z, ypred) %&gt;%\n  mutate(contr = `1` - `0`) %&gt;%\n  group_by(ppid, time) %&gt;%\n  do({\n    m0 &lt;- mean(.$`0`)\n    m1 &lt;- mean(.$`1`)\n    mc &lt;- mean(.$contr)\n    as_tibble(cbind(m0, m1, mc))\n  }) %&gt;%\n  ungroup() %&gt;%\n  group_by(time) %&gt;%\n  do({\n    q0 &lt;- t(quantile(.$m0, probs = prs))\n    q1 &lt;- t(quantile(.$m1, probs = prs))\n    contr &lt;- t(quantile(.$mc, probs = prs))\n    as_tibble(rbind(q0, q1, contr)) %&gt;%\n      mutate(var = c(\"Placebo\", \"Active\", \"Contrast\"))\n  })\n\n## Treatment difference, median & 90% CI errorbars\nppnd %&gt;%\n  filter(var != \"Contrast\") %&gt;%\n  ggplot(aes(\n    x = time,\n    y = `50%`,\n    ymin = `5%`,\n    ymax = `95%`,\n    colour = factor(var, levels = c(\"Placebo\", \"Active\"))\n  )) +\n  geom_pointrange(position = position_dodge(width = 0.3)) +\n  geom_line(position = position_dodge(width = 0.3)) +\n  scale_color_brewer(palette = \"Dark2\", name = \"\") +\n  paper_theme() +\n  theme(legend.position = c(0.15, 0.245),\n        legend.background = element_blank()) +\n  theme(\n    panel.border = element_rect(color = \"grey\", fill = NA, size = 0.25),\n    plot.title = element_text(size = 10, margin = rep(unit(\n      0.01 * 234, \"mm\"\n    ), 3)),\n    plot.subtitle = element_text(\n      size = 8,\n      color = rgb(0.3, 0.3, 0.3),\n      margin = rep(unit(0.001 * 234, \"mm\"), 3)\n    ),\n    axis.text.y = element_text(size = 8),\n    axis.text.x = element_text(size = 8),\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10)\n  ) +\n  labs(\n    x = \"Week\",\n    y = \"Outcome\",\n    title = \"Active group improves over time\",\n    subtitle = \"Posterior median (90% credible interval)\"\n  )\n\n\n\n\nTreatment difference, median & 90% CI errorbars\n\n\n\n\nIt is worth emphasizing that this last plot should not be the only one generated, and probably not the only one shown either. Strongly reduced messaging graphs require a robust understanding of the underlying data, which can only be built through a workflow such as the one described above. Further, depending on the situation and the audience, they might be challenged as loaded or unscientific. (E.g., the apparently perfect linear trend in Figure 5 appears “unrealistic”.) It is therefore important to ensure and emphasize that this last plot derives from a model which (as every model) is intended to separate the signal from the noise, and that the choice of this model is justified by a thorough inspection of the data.\n\nppnd %&gt;%\n  filter(var == \"Contrast\" & time &gt; 0) %&gt;%\n  ggplot(aes(x = time, y = `50%`)) +\n  geom_ribbon(aes(ymin = `5%`, ymax = `95%`), fill = \"black\", alpha = 0.15) +\n  geom_point(size = 1.5) + geom_line(size = 1) +\n  geom_hline(yintercept = 0, linetype = 2)  +\n  labs(\n    x = \"Week\",\n    y = \"Treatment difference\",\n    title = \"Treatment effect increases over time\",\n    subtitle = \"Posterior median (90% credible interval)\"\n  ) +\n  geom_segment(\n    aes(\n      x = 0.98,\n      y = -0.01,\n      xend = 0.98,\n      yend = -3.5\n    ),\n    arrow = arrow(length = unit(0.02 * 234, \"mm\")),\n    alpha = 0.25\n  ) +\n  annotate(\n    \"text\",\n    label = \"Greater benefit\",\n    x = 1.4,\n    y = -3.4,\n    size = 5,\n    alpha = 0.75\n  ) +\n  paper_theme() +\n  theme(\n    panel.border = element_rect(color = \"grey\", fill = NA, size = 0.25),\n    plot.subtitle = element_text(size = 10, color = rgb(0.3, 0.3, 0.3))\n  )\n\n\n\n\nTreatment difference, median & 90% CI ribbon\n\n\n\n\n\nsessionInfo()\n\n## R version 4.3.0 (2023-04-21)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Ventura 13.6.3\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: Europe/Zurich\n## tzcode source: internal\n## \n## attached base packages:\n## [1] grid      stats     graphics  grDevices utils    \n## [6] datasets  methods   base     \n## \n## other attached packages:\n##  [1] RColorBrewer_1.1-3 data.table_1.14.8 \n##  [3] gridExtra_2.3      rstanarm_2.26.1   \n##  [5] Rcpp_1.0.10        caTools_1.18.2    \n##  [7] lubridate_1.9.2    forcats_1.0.0     \n##  [9] stringr_1.5.0      dplyr_1.1.2       \n## [11] purrr_1.0.1        readr_2.1.4       \n## [13] tidyr_1.3.0        tibble_3.2.1      \n## [15] ggplot2_3.4.2      tidyverse_2.0.0   \n## \n## loaded via a namespace (and not attached):\n##  [1] bitops_1.0-7         inline_0.3.19       \n##  [3] rlang_1.1.1          magrittr_2.0.3      \n##  [5] matrixStats_1.2.0    compiler_4.3.0      \n##  [7] loo_2.6.0            callr_3.7.3         \n##  [9] vctrs_0.6.2          reshape2_1.4.4      \n## [11] pkgconfig_2.0.3      crayon_1.5.2        \n## [13] fastmap_1.1.1        backports_1.4.1     \n## [15] ellipsis_0.3.2       labeling_0.4.2      \n## [17] utf8_1.2.3           threejs_0.3.3       \n## [19] promises_1.2.0.1     rmarkdown_2.22      \n## [21] markdown_1.7         tzdb_0.4.0          \n## [23] ps_1.7.5             nloptr_2.0.3        \n## [25] xfun_0.39            jsonlite_1.8.4      \n## [27] later_1.3.1          parallel_4.3.0      \n## [29] prettyunits_1.1.1    R6_2.5.1            \n## [31] dygraphs_1.1.1.6     stringi_1.7.12      \n## [33] StanHeaders_2.26.28  boot_1.3-28.1       \n## [35] rstan_2.32.3         knitr_1.43          \n## [37] zoo_1.8-12           base64enc_0.1-3     \n## [39] bayesplot_1.10.0     httpuv_1.6.11       \n## [41] Matrix_1.5-4         splines_4.3.0       \n## [43] igraph_1.6.0         timechange_0.2.0    \n## [45] tidyselect_1.2.0     abind_1.4-5         \n## [47] rstudioapi_0.14      yaml_2.3.7          \n## [49] codetools_0.2-19     miniUI_0.1.1.1      \n## [51] curl_5.0.0           processx_3.8.1      \n## [53] pkgbuild_1.4.2       lattice_0.21-8      \n## [55] plyr_1.8.8           shiny_1.7.5         \n## [57] withr_2.5.0          posterior_1.5.0     \n## [59] evaluate_0.21        survival_3.5-5      \n## [61] RcppParallel_5.1.7   xts_0.13.1          \n## [63] pillar_1.9.0         tensorA_0.36.2.1    \n## [65] checkmate_2.2.0      DT_0.28             \n## [67] stats4_4.3.0         shinyjs_2.1.0       \n## [69] distributional_0.3.2 generics_0.1.3      \n## [71] hms_1.1.3            rstantools_2.3.1.1  \n## [73] munsell_0.5.0        scales_1.2.1        \n## [75] minqa_1.2.5          gtools_3.9.4        \n## [77] xtable_1.8-4         glue_1.6.2          \n## [79] tools_4.3.0          shinystan_2.6.0     \n## [81] lme4_1.1-33          colourpicker_1.3.0  \n## [83] QuickJSR_1.0.9       crosstalk_1.2.0     \n## [85] colorspace_2.1-0     nlme_3.1-162        \n## [87] cli_3.6.1            fansi_1.0.4         \n## [89] V8_4.3.0             gtable_0.3.3        \n## [91] digest_0.6.31        farver_2.1.1        \n## [93] htmlwidgets_1.6.2    htmltools_0.5.5     \n## [95] lifecycle_1.0.3      mime_0.12           \n## [97] shinythemes_1.2.0    MASS_7.3-58.4"
  },
  {
    "objectID": "posts/401-case1-eda/401-case1-eda.html",
    "href": "posts/401-case1-eda/401-case1-eda.html",
    "title": "Exploratory exposure-response analysis",
    "section": "",
    "text": "This example illustrates the importance of understanding the scientific context when exploring data graphically. An exploratory data analysis is more than just “plotting data”; it can lead to a deeper understanding and inform next steps (Gabry et al. 2019; Gelman 2004). However, like an analysis that is poorly thought through, a poorly implemented graph can also deceive.\nConsider an inhaled drug intended to improve lung function, with the target site of action in the lung. The drug is also absorbed systemically from the lung. Suppose that the team wants to fine-tune the choice of a recommended dose. A typical starting point for this question is often a plot of the response variable of interest against a summary measure of plasma concentration (e.g. the area under the concentration time curve, AUC). Figure 1 shows such a plot, generated using the default settings of the R package ggplot2.\n\n## Read in data\nmy_data &lt;- \n  read_csv(\"../../data/401_case1_PKPDdataset_ard.csv\") %&gt;%\n  filter(CYCLE == 1)\n\n## Plot response vs exposure\nmy_data %&gt;%\n  ggplot(aes(x = AUC, y = sCHG)) + \n  geom_point() + \n  scale_y_continuous(breaks = seq(-800, 800, 200)) +  \n  theme_gray(base_size = 10) +\n  labs(x = \"RESN\", y = \"LIDV\", title = \"\")\n\n\n\n\nA scatterplot of response vs. exposure with ‘default’ ggplot theme. It is common during an exploratory data analysis to display variable names directly from source data rather than an informative description. For this example RESN = AUC0-24h (h*ug/mL) and LIDV = FEV1 change from baseline (mL).\n\n\n\n\nIn terms of good graphical principles, this plot leaves a fair bit to be desired. Several improvements are warranted, including proper axis scaling, gridlines, annotation, font size, etc. One particularly egregious issue is the lack of care in selecting axis labels, leaving programming labels for the plotted variables (presumably only then to make the effort of explaining them in a caption). An improved version is shown in Figure 2, addressing many of these formatting issues. With an added LOESS smoother (Cleveland 1979), we see a positive non-linear trend, suggesting a shallow sigmoidal exposure-response relationship.\n\nmy_data %&gt;%\n  ggplot(aes(x = AUC, y = sCHG)) + \n  geom_point(alpha = 0.7) + \n  geom_smooth(method = \"loess\", colour = \"red\") +\n  scale_x_log10(breaks = lbr, labels = llb) + \n  scale_y_continuous(breaks = seq(-800, 800, 200)) +\n  annotation_logticks(sides = \"b\") +\n  labs(\n    x = expression(paste(\"AUC0-24h (h*\",mu,\"g/mL)\", sep = \"\")),\n    y = \"FEV1 change from baseline (mL)\", \n    title = \"Exposure is positively associated with response\",\n    subtitle = \"Loess smoother (95% CI)\"\n    ) +\n  paper_theme() \n\n\n\n\nAn improved scatterplot of exposure vs. response, including a LOESS smoothing curve to help visualizing the trend.\n\n\n\n\nIt is tempting, especially when presented with a suboptimal graph, to immediately set about fixing the various graphical imperfections and produce a more appropriate and visually appealing version of the same graph. This is an example of selective attention, focusing on the detail but overlooking the higher purpose of the task (i.e. the “why”). Instead, let us now take a step back and revisit this example in the context of the first law of visual communication: have a clear purpose.\nWhy are we conducting an exposure-response analysis? Recall that the scientific interest is to fine-tune the dose, and that the drug is inhaled and acting locally in the lung. The implicit assumption of an exposure-response analysis is one of causality. Here, however, plasma concentration is unlikely to be on the causal path from dose to response. What would be a better way to address the scientific question of interest?\n\nmy_data %&gt;%\n  ggplot(aes(x = AUC, y = sCHG, colour = factor(DOSE))) + \n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_colour_brewer(palette = \"Set2\" , name = \"Dose (mg)\") + \n  scale_x_log10(breaks = lbr, labels = llb) + \n  scale_y_continuous(breaks = seq(-800, 800, 200)) + \n  annotation_logticks(sides = \"b\") +\n  labs(\n    x = expression(paste(\"AUC0-24h (h*\", mu, \"g/mL)\", sep = \"\")), \n    y = \"FEV1 change from baseline (mL)\", \n    title = \"Exposure is not a better predictor of response than dose\") + \n  paper_theme() + \n  theme(\n    legend.position = c(\"right\"),\n    legend.title = element_text(size = 10)\n    )\n\n\n\n\nVisualization of exposure and response within levels of dose. The scatterplot is fundamentally changed by revisiting the question of interest and then applying good graphical principles.\n\n\n\n\nConsider Figure 3, where instead of estimating an overall trend we now look at the trends within dose. Clearly, any apparent trends within dose do not follow a consistent pattern across doses. The only reason why exposure and response appeared associated in the previous two plots is that they share a common cause, namely dose. In other words, dose is a confounder in those plots, and indeed dose is a better predictor of response than systemic concentration. We should build a dose-response model, rather than an exposure-response model, and choose a recommended dose based on this (and any information on safety and tolerability).\n\nsessionInfo()\n\n## R version 4.3.0 (2023-04-21)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Ventura 13.6.3\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \n## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## time zone: Europe/Zurich\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets \n## [6] methods   base     \n## \n## other attached packages:\n##  [1] RColorBrewer_1.1-3 lubridate_1.9.2   \n##  [3] forcats_1.0.0      stringr_1.5.0     \n##  [5] dplyr_1.1.2        purrr_1.0.1       \n##  [7] readr_2.1.4        tidyr_1.3.0       \n##  [9] tibble_3.2.1       ggplot2_3.4.2     \n## [11] tidyverse_2.0.0   \n## \n## loaded via a namespace (and not attached):\n##  [1] utf8_1.2.3        generics_0.1.3    lattice_0.21-8   \n##  [4] stringi_1.7.12    hms_1.1.3         digest_0.6.31    \n##  [7] magrittr_2.0.3    evaluate_0.21     grid_4.3.0       \n## [10] timechange_0.2.0  fastmap_1.1.1     Matrix_1.5-4     \n## [13] jsonlite_1.8.4    mgcv_1.8-42       fansi_1.0.4      \n## [16] scales_1.2.1      cli_3.6.1         rlang_1.1.1      \n## [19] crayon_1.5.2      splines_4.3.0     bit64_4.0.5      \n## [22] munsell_0.5.0     withr_2.5.0       yaml_2.3.7       \n## [25] tools_4.3.0       parallel_4.3.0    tzdb_0.4.0       \n## [28] colorspace_2.1-0  vctrs_0.6.2       R6_2.5.1         \n## [31] lifecycle_1.0.3   htmlwidgets_1.6.2 bit_4.0.5        \n## [34] vroom_1.6.3       pkgconfig_2.0.3   pillar_1.9.0     \n## [37] gtable_0.3.3      glue_1.6.2        xfun_0.39        \n## [40] tidyselect_1.2.0  rstudioapi_0.14   knitr_1.43       \n## [43] farver_2.1.1      nlme_3.1-162      htmltools_0.5.5  \n## [46] rmarkdown_2.22    labeling_0.4.2    compiler_4.3.0\n\n\n\n\n\n\nReferences\n\nCleveland, William S. 1979. “Robust Locally Weighted Regression and Smoothing Scatterplots.” Journal of the American Statistical Association 74 (368): 829–36. https://doi.org/10.1080/01621459.1979.10481038.\n\n\nGabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. 2019. “Visualization in Bayesian Workflow.” Journal of the Royal Statistical Society: Series A (Statistics in Society) 182 (2): 389–402. https://doi.org/10.1111/rssa.12378.\n\n\nGelman, Andrew. 2004. “Exploratory Data Analysis for Complex Models.” Journal of Computational and Graphical Statistics 13 (4): 755–79. https://doi.org/10.1198/106186004X11435."
  },
  {
    "objectID": "posts/101-intro-vizcom/101-intro-vizcom.html",
    "href": "posts/101-intro-vizcom/101-intro-vizcom.html",
    "title": "Effective visual communication",
    "section": "",
    "text": "Effective visual communication is a core competency for pharmacometricians, statisticians, and more generally any quantitative scientist. It is essential in every step of a quantitative workflow, from scoping to execution and communicating results and conclusions. With this competency, we can better understand data and influence decisions towards appropriate actions. Without it, we can fool ourselves and others and pave the way to wrong conclusions and actions. The goal of this tutorial is to convey this competency.\nWe posit three laws of effective visual communication for the quantitative scientist:\n\nhave a clear purpose,\nshow the data clearly,\nand make the message obvious.\n\nWe defined the three laws of effective visual communication to provide overarching principled advice that can serve as a guiding star towards effective visual communication for the quantitative scientist. A concise Cheat Sheet, distills more granular recommendations for everyday practical use. Finally, these laws and recommendations are illustrated in four case studies. The aim of this site is to provide both the code, data and examples as stand alone posts. We hope that it proves useful for putting the three laws into practice.\nTo further ease implementation in practice, it helps to distill the three laws in to even more detailed recommendations and illustrate them concretely. This is why we introduced a cheat Sheet. This single-page reference sheet is an integral part of this tutorial, carefully designed as a concise and accessible resource for everyday practical use. Yet, it draws from a wide range of sources including (Bonate 2014; Jean L. Doumont 2002; Cairo 2016; Few 2012; Ware 2004; B. Wong 2010, 2011; J. L. Doumont 2009; Heer and Bostock 2010; Tufte 1986, 1997; Gelman and Unwin 2013; D. M. Wong 2010; Wainer 1984; Munzner 2015; Cleveland 1985; Cleveland and McGill 1985, 1987; Wilkinson 2005; Tukey 1977; Duke et al. 2015; Robbins 2012).\nThe full version is available along with corresponding programming code in R.\nThe full published tutorial can is available and online at CPT:PSP here.\nA pre-print of the complete tutorial can also be found at: https://arxiv.org/abs/1903.09512\n\n\n\n\nReferences\n\nBonate, Peter L. 2014. Be a Model Communicator and Sell Your Models to Anyone. Published by Peter Bonate. https://www.amazon.com/Be-Model-Communicator-Models-2014-10-06/dp/B01LP3SHNM.\n\n\nCairo, Alberto. 2016. The Truthful Art: Data, Charts, and Maps for Communication. 1st ed. Thousand Oaks, CA, USA: New Riders Publishing.\n\n\nCleveland, William S. 1985. The Elements of Graphing Data. Belmont, CA, USA: Wadsworth Publ. Co.\n\n\nCleveland, William S., and Robert McGill. 1985. “Graphical Perception and Graphical Methods for Analyzing Scientific Data.” Science 229 (4716): 828–33. https://doi.org/10.1126/science.229.4716.828.\n\n\n———. 1987. “Graphical Perception: The Visual Decoding of Quantitative Information on Graphical Displays of Data.” Journal of the Royal Statistical Society Series A 150 (3): 192–229. http://www.jstor.org/stable/2981473.\n\n\nDoumont, J. L. 2009. Trees, Maps, and Theorems: Effective Communication for Rational Minds. Principiae. https://books.google.com/books?id=O2dFPgAACAAJ.\n\n\nDoumont, Jean L. 2002. “The Three Laws of Professional Communication.” IEEE Transactions on Professional Communication 45 (4): 291–96. https://doi.org/10.1109/TPC.2002.805164.\n\n\nDuke, Susan P., Fabrice Bancken, Brenda Crowe, Mat Soukup, Taxiarchis Botsis, and Richard Forshee. 2015. “Seeing Is Believing: Good Graphic Design Principles for Medical Research.” Statistics in Medicine 34 (22): 3040–59. https://doi.org/10.1002/sim.6549.\n\n\nFew, Stephen. 2012. Show Me the Numbers: Designing Tables and Graphs to Enlighten. 2nd ed. USA: Analytics Press.\n\n\nGelman, Andrew, and Antony Unwin. 2013. “Infovis and Statistical Graphics: Different Goals, Different Looks.” Journal of Computational and Graphical Statistics 22 (1): 2–28. https://doi.org/10.1080/10618600.2012.761137.\n\n\nHeer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design.” In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 203–12. CHI ’10. New York, NY, USA: ACM. https://doi.org/10.1145/1753326.1753357.\n\n\nMunzner, Tamara. 2015. Visualization Analysis and Design. AK Peters Visualization Series. CRC Press. https://books.google.de/books?id=NfkYCwAAQBAJ.\n\n\nRobbins, Naomi B. 2012. Creating More Effective Graphs. Wiley. https://www.amazon.com/Creating-Effective-Graphs-Naomi-Robbins/dp/0985911123.\n\n\nTufte, Edward R. 1986. The Visual Display of Quantitative Information. Cheshire, CT, USA: Graphics Press.\n\n\n———. 1997. Visual Explanations: Images and Quantities, Evidence and Narrative. Cheshire, CT, USA: Graphics Press.\n\n\nTukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley.\n\n\nWainer, Howard. 1984. “How to Display Data Badly.” The American Statistician 38 (2): 137–47. https://doi.org/10.1080/00031305.1984.10483186.\n\n\nWare, Colin. 2004. Information Visualization: Perception for Design. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics (Statistics and Computing). Berlin, Heidelberg: Springer-Verlag.\n\n\nWong, Bang. 2010. “Points of View: Gestalt Principles (Part 1).” Nature Methods 7: 863–63.\n\n\n———. 2011. “Points of View: Simplify to Clarify.” Nature Methods 8 (8): 611. https://www.nature.com/articles/nmeth.1660.\n\n\nWong, D. M. 2010. The Wall Street Journal Guide to Information Graphics: The Dos and Don’ts of Presenting Data, Facts, and Figures. W.W. Norton & Company. https://books.google.com/books?id=RmaJPgAACAAJ."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Case studies",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nEffective visual communication\n\n\n\n\n\n\n\nintroduction\n\n\n\n\nA tutorial on effective visual communication for the quantitative scientist.\n\n\n\n\n\n\nDec 19, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\nThree laws of visual communication\n\n\n\n\n\n\n\nthree laws\n\n\nprinciples\n\n\n\n\nfor the quantitative scientist. Effective visual communication follows three laws: 1.) Have a clear purpose; 2.) Show the data clearly; and 3.) Make the message obvious. These three laws correspond to the three main ingredients of any quantitative work: purpose, data, and message. Getting these right leads to success; failing in any of them leads to overall failure.\n\n\n\n\n\n\nDec 19, 2023\n\n\n10 min\n\n\n\n\n\n\n\n\nGraphics Principles Cheat Sheet\n\n\n\n\n\n\n\ncheat sheet\n\n\nprinciples\n\n\n\n\nA concise and accessible resource for everyday practical use.\n\n\n\n\n\n\nDec 19, 2023\n\n\n1 min\n\n\n\n\n\n\n\n\nExploratory exposure-response analysis\n\n\n\n\n\n\n\ncase studies\n\n\nexample code\n\n\nEDA\n\n\nworkflow\n\n\n\n\nThe importance of understanding the scientific context.\n\n\n\n\n\n\nDec 19, 2023\n\n\n5 min\n\n\n\n\n\n\n\n\nPharmacokinetic exposure by ethnicity\n\n\n\n\n\n\n\ncase studies\n\n\nexample code\n\n\nPK/PD\n\n\nsubgroups\n\n\n\n\nClarifying the purpose.\n\n\n\n\n\n\nDec 19, 2023\n\n\n11 min\n\n\n\n\n\n\n\n\nWhy a waterfall plot?\n\n\n\n\n\n\n\ncase studies\n\n\nexample code\n\n\nwaterfall plot\n\n\ndefaults\n\n\n\n\nQuestioning the defaults.\n\n\n\n\n\n\nDec 19, 2023\n\n\n13 min\n\n\n\n\n\n\nNo matching items"
  }
]